{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh_eZXOfrw1O",
        "colab_type": "code",
        "outputId": "5453d229-1a07-4d6c-af0f-a91b0ae422df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu==2.0.0-beta0\n",
        "!pip install tensorflow-addons"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-beta0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/7e/87c4c94686cda7066f52cbca4c344248516490acdd6b258ec6b8a805d956/tensorflow_gpu-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl (348.8MB)\n",
            "\u001b[K     |████████████████████████████████| 348.9MB 50kB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.8.1)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 17.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.17.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (45.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (0.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta0) (2.8.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b0 tf-estimator-nightly-1.14.0.dev2019060501\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/3c/bec5beabc6f44becb0e5a494c984612d13b49d662131c3eaed328126abbc/tensorflow_addons-0.8.1-cp36-cp36m-manylinux2010_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.7MB/s \n",
            "\u001b[?25hCollecting typeguard\n",
            "  Downloading https://files.pythonhosted.org/packages/06/37/d236aec27f8a8eed66f1a17116eb51684528cf8005a6883f879fe2e842ae/typeguard-2.7.1-py3-none-any.whl\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.8.1 typeguard-2.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLu3YVHlSco4",
        "colab_type": "code",
        "outputId": "f13d3eae-64c7-466d-9b4c-b912cbafd2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import pandas as pd\n",
        "import tensorflow.keras as k\n",
        "import tensorflow.keras.layers as l\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow_addons as tfa\n",
        "import random\n",
        "import cv2\n",
        "import tensorboard\n",
        "import datetime\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "from keras import optimizers\n",
        "from tensorboard import notebook\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WgdPVe8Szkz",
        "colab_type": "code",
        "outputId": "6c32b427-5ce6-4e30-c5f6-8dcf8e7af46f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd0JP6UvS5eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buffersize = 50\n",
        "batchsize = 30\n",
        "N_samples = 413\n",
        "N_trainingsamples = 383\n",
        "N_validationsamples = 30\n",
        "N_prefetch = 8 \n",
        "N_parallel_iteration = 4\n",
        "N_testsamples = 103\n",
        "\n",
        "\n",
        "\"\"\"Define 5 augmentation functions\"\"\"\n",
        "@tf.function\n",
        "def flip1(img):\n",
        "   img_flipped = tf.image.random_flip_up_down(img)\n",
        "   img = tf.cast(img_flipped, tf.float32) / 255.0\n",
        "   return img\n",
        "\n",
        "def flip2(img):\n",
        "   img_flipped = tf.image.random_flip_left_right(img)\n",
        "   img = tf.cast(img_flipped, tf.float32) / 255.0\n",
        "   return img\n",
        "\n",
        "    \n",
        "def rotate(img):\n",
        "    angles = tf.random.uniform([], minval=0, maxval=359, dtype=tf.dtypes.float32)\n",
        "    img = tfa.image.rotate(img, angles, interpolation='NEAREST', name=None)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def zoom(img):\n",
        "    scales = list(np.arange(0.8, 1.0, 0.01))\n",
        "    boxes = np.zeros((len(scales), 2))\n",
        "\n",
        "    for i, scale in enumerate(scales):\n",
        "        x1 = 0.5 - (0.5 * scale)\n",
        "        y1 = 0.5 + (0.5 * scale)\n",
        "        boxes[i] = [x1, y1]\n",
        "    # Create different crops for an image\n",
        "    img = tf.image.crop_and_resize(img, boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(256, 256))\n",
        "    # Create different crops for an image\n",
        "    crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)),\n",
        "                                             crop_size=(256, 256))\n",
        "    # Return a random crop\n",
        "    return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
        "            \n",
        "\n",
        "def rot90(img):\n",
        "    img = tf.image.rot90(img, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tztfQrbgilL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"build training and validation labels before spliting\"\"\"\n",
        "\n",
        "csv_path = \"/content/drive/My Drive/Masterlab/a. IDRiD_Disease Grading_Training Labels.csv\"\n",
        "files_csv = pd.read_csv(csv_path, usecols=[1])\n",
        "\n",
        "\"\"\"The only difference of the input pipeline for transfer learning model is the reducion of the label dimmensions.\n",
        "The labels are defined as numpy arrays with one axis.\"\"\"\n",
        "\n",
        "labels = np.zeros(shape=(N_samples,))  # save training and validation labels in one-hot coding form\n",
        "csv_tensor = tf.convert_to_tensor(files_csv.values, dtype=tf.int32)\n",
        "csv_tensor = tf.map_fn(lambda x: 1 if x > 1 else 0, files_csv.values)\n",
        "for i in range(N_samples):\n",
        "    if csv_tensor[i] == 1:\n",
        "         labels[i][0] = 1\n",
        "    else:\n",
        "         labels[i][1] = 1\n",
        "\n",
        "\n",
        "\"\"\"Read training and validation image files from folder\"\"\"\n",
        "def load_file_names():\n",
        "    files = glob.glob(\"/content/drive/My Drive/Masterlab/a. Training Set/*.jpg\")\n",
        "    return files\n",
        "\n",
        "\n",
        "img_list = []\n",
        "files = sorted(load_file_names())\n",
        "\n",
        "\n",
        "\"\"\"The parse function converts a datapair(file, label) to a correspoding datapair(image, label)\"\"\"\n",
        "def parse_train_function(files,labels):\n",
        "    image_string = tf.io.read_file(files)\n",
        "    image_decoded = tf.io.decode_jpeg(image_string)                # image is decoded\n",
        "    image_resized = tf.image.resize_with_pad(image_decoded,        # image is normalized\n",
        "                                             256,\n",
        "                                             256)\n",
        " \n",
        "    a = random.randint(1,10)              # chose a way to be augmented\n",
        "    if a == 1:\n",
        "      img = zoom(image_resized)\n",
        "      img = tf.cast(img, tf.float32) / 255.0  \n",
        "    elif a== 2:\n",
        "      img = rotate(image_resized)\n",
        "    elif a== 3:\n",
        "      img = rot90(image_resized)\n",
        "    elif a== 4:\n",
        "      img = zoom(image_resized)    \n",
        "    elif a== 5:\n",
        "      img = flip1(image_resized)\n",
        "    elif a== 6:\n",
        "      img = flip2(image_resized)    \n",
        "    else:\n",
        "      img = image_resized  \n",
        "      img = tf.cast(img, tf.float32) / 255.0       \n",
        "    label = labels\n",
        "    return img, label\n",
        "\n",
        "\n",
        "\"\"\"validation datapair will be created as training datapair, but without data augmentation\"\"\"\n",
        "def parse_val_function(files,labels): \n",
        "    image_string = tf.io.read_file(files)\n",
        "    image_decoded = tf.io.decode_jpeg(image_string)\n",
        "    image_resized = tf.image.resize_with_pad(image_decoded,\n",
        "                                             256,\n",
        "                                             256)\n",
        "    img = tf.cast(image_resized, tf.float32) / 255.0\n",
        "    label = labels\n",
        "    return img, label\n",
        "\n",
        "\"\"\"Build training dataset with its parse fuction\"\"\"\n",
        "def build_train_ds(files, labels, batchsize):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((files, labels))\n",
        "    ds = ds.map(parse_train_function, N_parallel_iteration)\n",
        "    ds = ds.shuffle(380).batch(batchsize).repeat(-1).prefetch(N_prefetch)\n",
        "    return ds\n",
        "\n",
        "\n",
        "\"\"\"Build validation dataset with its parse fuction\"\"\"\n",
        "def build_val_ds(files, labels, batchsize):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((files, labels))\n",
        "    ds = ds.map(parse_val_function, N_parallel_iteration)\n",
        "    ds = ds.shuffle(20).batch(30).prefetch(N_prefetch)\n",
        "    return ds\n",
        "\n",
        "\n",
        "\"\"\"Shuffle the index of file paths. It shortens the running time comparing to shuffling the a dataset with decoded images and labels\"\"\"\n",
        "shuffle_idx = np.arange(0, N_samples)\n",
        "np.random.shuffle(shuffle_idx)\n",
        "files = [files[i] for i in shuffle_idx]\n",
        "labels = [labels[i] for i in shuffle_idx]\n",
        "\n",
        "\n",
        "\"\"\"Split the training and validation datasets by file path index\"\"\"\n",
        "train_ds = build_train_ds(files[0:N_trainingsamples], labels[0:N_trainingsamples], batchsize)\n",
        "val_ds = build_val_ds(files[N_trainingsamples:N_samples], labels[N_trainingsamples:N_samples], batchsize)\n",
        "\n",
        "\n",
        "\"\"\"load the original images to check if file path are correct\"\"\"\n",
        "img = plt.imread(files[100])\n",
        "plt.imshow(img)\n",
        "plt.title(labels[100])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj74jwTRgiXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Build testing dataset of images\"\"\"\n",
        "N_testsamples = 103\n",
        "\n",
        "def load_testfile_names():\n",
        "    files = glob.glob(\"/content/drive/My Drive/Masterlab/b. Testing Set/*.jpg\")\n",
        "    return files\n",
        "\n",
        "\n",
        "img_list_test = []\n",
        "test_files = load_testfile_names()\n",
        "\n",
        "for file in sorted(test_files):\n",
        "    image_string = tf.io.read_file(file)\n",
        "    image_decoded = tf.io.decode_image(image_string)\n",
        "    image_resized = tf.image.resize_with_pad(image_decoded,   # Normalize image\n",
        "                                             256,\n",
        "                                             256)\n",
        "    img = tf.cast(image_resized, tf.float32) / 255.0          # Normalize image\n",
        "    img_list_test.append(img)\n",
        "    \n",
        "img_tensor_test = tf.convert_to_tensor(img_list_test, dtype=tf.float32)\n",
        "img_test_ds = tf.data.Dataset.from_tensor_slices(img_tensor_test)\n",
        "\n",
        "\n",
        "\"\"\"Load test label files\"\"\"\n",
        "csv_path_test = \"/content/drive/My Drive/Masterlab/b. IDRiD_Disease Grading_Testing Labels.csv\"\n",
        "files_csv_test = pd.read_csv(csv_path_test, usecols=[1])\n",
        "\n",
        "\"\"\"The only difference of the input pipeline for transfer learning model is the reducion of the label dimmensions.\n",
        "The labels are defined as numpy arrays with one axis.\"\"\"\n",
        "\n",
        "t = np.zeros(shape=(103,))      # Build test labels in one-hot coding form\n",
        "csv_tensor = tf.convert_to_tensor(files_csv_test.values, dtype=tf.float32)\n",
        "csv_tensor = tf.map_fn(lambda x: 1 if x > 1 else 0, csv_tensor)\n",
        "for i in range(N_testsamples):\n",
        "    if csv_tensor[i] == 1:\n",
        "         t[i][0] = 1\n",
        "    else:\n",
        "         t[i][1] = 1\n",
        "\n",
        "\n",
        "\"\"\"build testing dataset of labels\"\"\"\n",
        "labels_ds_test = tf.data.Dataset.from_tensor_slices(t)\n",
        "test_ds = tf.data.Dataset.zip((img_test_ds, labels_ds_test)).batch(batchsize)   # Combine the image dataset and label dataset for testset together"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnzGbaPGhaIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build total dataset(testing set)\n",
        "test_ds = tf.data.Dataset.zip((img_test_ds, labels_ds_test)).batch(batchsize)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}